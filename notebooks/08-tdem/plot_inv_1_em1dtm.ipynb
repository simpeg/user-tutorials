{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# 1D Inversion of Time-Domain Data for a Single Sounding\n\nHere we use the module *SimPEG.electromangetics.time_domain_1d* to invert\ntime domain data and recover a 1D electrical conductivity model.\nIn this tutorial, we focus on the following:\n\n    - How to define sources and receivers from a survey file\n    - How to define the survey\n    - Sparse 1D inversion of with iteratively re-weighted least-squares\n\nFor this tutorial, we will invert 1D time domain data for a single sounding.\nThe end product is layered Earth model which explains the data. The survey\nconsisted of a horizontal loop with a radius of 6 m, located 20 m above the\nsurface. The receiver measured the vertical component of the magnetic flux\nat the loop's centre.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import modules\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nimport tarfile\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom discretize import TensorMesh\n\nimport SimPEG.electromagnetics.time_domain as tdem\n\nfrom SimPEG.utils import mkvc, plot_1d_layer_model\nfrom SimPEG import (\n    maps,\n    data,\n    data_misfit,\n    inverse_problem,\n    regularization,\n    optimization,\n    directives,\n    inversion,\n    utils,\n)\n\nplt.rcParams.update({\"font.size\": 16, \"lines.linewidth\": 2, \"lines.markersize\": 8})\n\n# sphinx_gallery_thumbnail_number = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Download Test Data File\n\nHere we provide the file path to the data we plan on inverting.\nThe path to the data file is stored as a\ntar-file on our google cloud bucket:\n\"https://storage.googleapis.com/simpeg/doc-assets/em1dtm.tar.gz\"\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# storage bucket where we have the data\ndata_source = \"https://storage.googleapis.com/simpeg/doc-assets/em1dtm.tar.gz\"\n\n# download the data\ndownloaded_data = utils.download(data_source, overwrite=True)\n\n# unzip the tarfile\ntar = tarfile.open(downloaded_data, \"r\")\ntar.extractall()\ntar.close()\n\n# path to the directory containing our data\ndir_path = downloaded_data.split(\".\")[0] + os.path.sep\n\n# files to work with\ndata_filename = dir_path + \"em1dtm_data.txt\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Data and Plot\n\nHere we load and plot the 1D sounding data. In this case, we have the B-field\nresponse to a step-off waveform.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Load field data\ndobs = np.loadtxt(str(data_filename), skiprows=1)\n\ntimes = dobs[:, 0]\ndobs = mkvc(dobs[:, -1])\n\nfig = plt.figure(figsize=(7, 7))\nax = fig.add_axes([0.15, 0.15, 0.8, 0.75])\nax.loglog(times, np.abs(dobs), \"k-o\", lw=3)\nax.set_xlabel(\"Times (s)\")\nax.set_ylabel(\"|B| (T)\")\nax.set_title(\"Observed Data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining the Survey\n\nHere we demonstrate a general way to define the receivers, sources, waveforms and survey.\nFor this tutorial, we define a single horizontal loop source as well\na receiver which measures the vertical component of the magnetic flux.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Source loop geometry\nsource_location = np.array([0.0, 0.0, 20.0])\nsource_orientation = \"z\"  # \"x\", \"y\" or \"z\"\nsource_current = 1.0  # peak current amplitude\nsource_radius = 6.0  # loop radius\n\n# Receiver geometry\nreceiver_location = np.array([0.0, 0.0, 20.0])\nreceiver_orientation = \"z\"  # \"x\", \"y\" or \"z\"\n\n# Receiver list\nreceiver_list = []\nreceiver_list.append(\n    tdem.receivers.PointMagneticFluxDensity(\n        receiver_location, times, orientation=receiver_orientation\n    )\n)\n\n# Define the source waveform.\nwaveform = tdem.sources.StepOffWaveform()\n\n# Sources\nsource_list = [\n    tdem.sources.CircularLoop(\n        receiver_list=receiver_list,\n        location=source_location,\n        waveform=waveform,\n        current=source_current,\n        radius=source_radius,\n    )\n]\n\n# Survey\nsurvey = tdem.Survey(source_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Assign Uncertainties and Define the Data Object\n\nHere is where we define the data that are inverted. The data are defined by\nthe survey, the observation values and the uncertainties.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# 5% of the absolute value\nuncertainties = 0.05 * np.abs(dobs) * np.ones(np.shape(dobs))\n\n# Define the data object\ndata_object = data.Data(survey, dobs=dobs, standard_deviation=uncertainties)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining a 1D Layered Earth (1D Tensor Mesh)\n\nHere, we define the layer thicknesses for our 1D simulation. To do this, we use\nthe TensorMesh class.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Layer thicknesses\ninv_thicknesses = np.logspace(0, 1.5, 25)\n\n# Define a mesh for plotting and regularization.\nmesh = TensorMesh([(np.r_[inv_thicknesses, inv_thicknesses[-1]])], \"0\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define a Starting and Reference Model\n\nHere, we create starting and/or reference models for the inversion as\nwell as the mapping from the model space to the active cells. Starting and\nreference models can be a constant background value or contain a-priori\nstructures. Here, the starting model is log(0.1) S/m.\n\nDefine log-conductivity values for each layer since our model is the\nlog-conductivity. Don't make the values 0!\nOtherwise the gradient for the 1st iteration is zero and the inversion will\nnot converge.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Define model. A resistivity (Ohm meters) or conductivity (S/m) for each layer.\nstarting_model = np.log(0.1 * np.ones(mesh.nC))\n\n# Define mapping from model to active cells.\nmodel_mapping = maps.ExpMap()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the Physics using a Simulation Object\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "simulation = tdem.Simulation1DLayered(\n    survey=survey, thicknesses=inv_thicknesses, sigmaMap=model_mapping\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define Inverse Problem\n\nThe inverse problem is defined by 3 things:\n\n    1) Data Misfit: a measure of how well our recovered model explains the field data\n    2) Regularization: constraints placed on the recovered model and a priori information\n    3) Optimization: the numerical approach used to solve the inverse problem\n\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Define the data misfit. Here the data misfit is the L2 norm of the weighted\n# residual between the observed data and the data predicted for a given model.\n# The weighting is defined by the reciprocal of the uncertainties.\ndmis = data_misfit.L2DataMisfit(simulation=simulation, data=data_object)\ndmis.W = 1.0 / uncertainties\n\n# Define the regularization (model objective function)\nreg_map = maps.IdentityMap(nP=mesh.nC)\nreg = regularization.Sparse(mesh, mapping=reg_map, alpha_s=0.01, alpha_x=1.0)\n\n# set reference model\nreg.mref = starting_model\n\n# Define sparse and blocky norms p, q\nreg.norms = [1, 0]\n\n# Define how the optimization problem is solved. Here we will use an inexact\n# Gauss-Newton approach that employs the conjugate gradient solver.\nopt = optimization.ProjectedGNCG(maxIter=100, maxIterLS=20, maxIterCG=30, tolCG=1e-3)\n\n# Define the inverse problem\ninv_prob = inverse_problem.BaseInvProblem(dmis, reg, opt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define Inversion Directives\n\nHere we define any directiveas that are carried out during the inversion. This\nincludes the cooling schedule for the trade-off parameter (beta), stopping\ncriteria for the inversion and saving inversion results at each iteration.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Defining a starting value for the trade-off parameter (beta) between the data\n# misfit and the regularization.\nstarting_beta = directives.BetaEstimate_ByEig(beta0_ratio=1e1)\n\n# Update the preconditionner\nupdate_Jacobi = directives.UpdatePreconditioner()\n\n# Options for outputting recovered models and predicted data for each beta.\nsave_iteration = directives.SaveOutputEveryIteration(save_txt=False)\n\n# Directives for the IRLS\nupdate_IRLS = directives.Update_IRLS(\n    max_irls_iterations=30, minGNiter=1, coolEpsFact=1.5, update_beta=True\n)\n\n# Updating the preconditionner if it is model dependent.\nupdate_jacobi = directives.UpdatePreconditioner()\n\n# Add sensitivity weights\nsensitivity_weights = directives.UpdateSensitivityWeights()\n\n# The directives are defined as a list.\ndirectives_list = [\n    sensitivity_weights,\n    starting_beta,\n    save_iteration,\n    update_IRLS,\n    update_jacobi,\n]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Running the Inversion\n\nTo define the inversion object, we need to define the inversion problem and\nthe set of directives. We can then run the inversion.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Here we combine the inverse problem and the set of directives\ninv = inversion.BaseInversion(inv_prob, directives_list)\n\n# Run the inversion\nrecovered_model = inv.run(starting_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plotting Results\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Load the true model and layer thicknesses\ntrue_model = np.array([0.1, 1.0, 0.1])\ntrue_layers = np.r_[40.0, 40.0, 160.0]\n\n# Extract Least-Squares model\nl2_model = inv_prob.l2model\nprint(np.shape(l2_model))\n\n# Plot true model and recovered model\nfig = plt.figure(figsize=(8, 9))\nx_min = np.min(\n    np.r_[model_mapping * recovered_model, model_mapping * l2_model, true_model]\n)\nx_max = np.max(\n    np.r_[model_mapping * recovered_model, model_mapping * l2_model, true_model]\n)\n\nax1 = fig.add_axes([0.2, 0.15, 0.7, 0.7])\nplot_1d_layer_model(true_layers, true_model, ax=ax1, show_layers=False, color=\"k\")\nplot_1d_layer_model(\n    mesh.h[0], model_mapping * l2_model, ax=ax1, show_layers=False, color=\"b\"\n)\nplot_1d_layer_model(\n    mesh.h[0], model_mapping * recovered_model, ax=ax1, show_layers=False, color=\"r\"\n)\nax1.set_xlim(0.01, 10)\nax1.grid()\nax1.set_title(\"True and Recovered Models\")\nax1.legend([\"True Model\", \"L2-Model\", \"Sparse Model\"])\nplt.gca().invert_yaxis()\n\n# Plot predicted and observed data\ndpred_l2 = simulation.dpred(l2_model)\ndpred_final = simulation.dpred(recovered_model)\n\nfig = plt.figure(figsize=(7, 7))\nax1 = fig.add_axes([0.15, 0.15, 0.8, 0.75])\nax1.loglog(times, np.abs(dobs), \"k-o\")\nax1.loglog(times, np.abs(dpred_l2), \"b-o\")\nax1.loglog(times, np.abs(dpred_final), \"r-o\")\nax1.grid()\nax1.set_xlabel(\"times (Hz)\")\nax1.set_ylabel(\"|Hs/Hp| (ppm)\")\nax1.set_title(\"Predicted and Observed Data\")\nax1.legend([\"Observed\", \"L2-Model\", \"Sparse\"], loc=\"upper right\")\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}